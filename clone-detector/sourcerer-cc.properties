#Sourcerer-CC-D specific
NODE_PREFIX=NODE
QUERY_DIR_PATH=query/dataset
# source will be put here by the clone-detector
QUERY_SRC_PATH=query/query.code
OUTPUT_DIR=${NODE_PREFIX}/output
DATASET_DIR_PATH=input/dataset
 # Source code should go here - should be same format from parsing
DATASET_SRC_PATH=input/test.code
IS_GEN_CANDIDATE_STATISTICS=false
IS_STATUS_REPORTER_ON=true
#for recovery
LOG_PROCESSED_LINENUMBER_AFTER_X_LINES=50
# Ignore all files outside these bounds
#num_tokens,num_unique_tokens,num_statements,num_expressions,num_assignments
METRICS_ORDER_IN_SHARDS=num_tokens
IS_SHARDING=true

DATASET_HEADER_FILE_PATH=input/test.header
DATASET_LICENSE_FILE_PATH=input/test.license
QUERY_HEADER_FILE_PATH=query/query.header
QUERY_LICENSE_FILE_PATH=query/query.license

# Sharding speeds up search for very large datasets (>200K files).
# For small-ish datasets, it doesn't matter so much

SEARCH_SHARDS=ALL

# Tier 1 shards based on num tokens
LEVEL_1_MIN_TOKENS=23
LEVEL_1_MAX_TOKENS=500000
LEVEL_1_SHARD_MAX_NUM_TOKENS=28,50,75,120,200,350,600,950

# The next few variables serve for tuning performance.
# Their values depend, in part, on how many cores are available.
# The default values work well for 1 single SourcererCC process 
# on an 8-core machine.
# in gigabytes
MAX_INDEX_SIZE=12
# I don't think the max index variable is used

RCQ_THREADS=1

MANAGER_IP=localhost
MANAGER_PORT=4567